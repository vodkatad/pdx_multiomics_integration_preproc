{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "State notebook purpose here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Import libraries and write settings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Introduction\n",
    "# Train, optimise stacked predictor of Cetuximab sensitivity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "# optuna + visulization\n",
    "import mlflow\n",
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as ipyw\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pickle\n",
    "#from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, multilabel_confusion_matrix, auc, matthews_corrcoef, roc_auc_score, accuracy_score, classification_report, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "from sklearn.feature_selection import f_classif, SelectKBest, SelectPercentile, VarianceThreshold, chi2, SelectFromModel\n",
    "from sklearn import model_selection\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from mlxtend.classifier import LogisticRegression as extLogisticRegression\n",
    "from mlxtend.classifier import StackingClassifier, StackingCVClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from typing import no_type_check_decorator\n",
    "\n",
    "# Options for pandas\n",
    "# No warnings about setting value on copy of slice\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 600\n",
    "pd.options.display.max_rows = 30\n",
    "\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sb\n",
    "# Set default font size\n",
    "plt.rcParams['font.size'] = 24\n",
    "# Set default font size\n",
    "sb.set(font_scale=.8)\n",
    "custom_style = {'axes.labelcolor': 'black',\n",
    "                'xtick.color': 'black',\n",
    "                'ytick.color': 'black'}\n",
    "sb.set_style(\"white\", rc=custom_style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis/Modeling\n",
    "Do work here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '../../../dataset/6_tuning/'\n",
    "suffix = 0\n",
    "class input:\n",
    "        mut = datadir + f\"preproc_mut{suffix}.tsv\"\n",
    "        cnv = datadir + f\"preproc_CNV.tsv\"\n",
    "        raw_expr = datadir + \"expr_merge.tsv\"\n",
    "        expr = datadir + f\"preproc_expr{suffix}.tsv\"\n",
    "        meth = datadir + f\"preproc_meth{suffix}.tsv\"\n",
    "        clin = datadir + f\"preproc_clin{suffix}.tsv\"\n",
    "        response = datadir + f\"DrugResponse_LMXfirslevel_trainTest{suffix}.tsv\"\n",
    "class output:\n",
    "\tX_train = f\"mutCross+clin+exprPROGENyHALLMARKS+highCNagg+MethK5cluster{suffix}_Xtrain.tsv\"\n",
    "\tX_test = f\"mutCross+clin+exprPROGENyHALLMARKS+highCNagg+MethK5cluster{suffix}_Xtest.tsv\"\n",
    "\tY_train = f\"OmicsBinary{suffix}_Ytrain.tsv\"\n",
    "\tY_test = f\"OmicsBinary{suffix}_Ytest.tsv\"\n",
    "\tbest_model = f\"OmicsBinary_StackingCVClassifier_mutCross+clin+exprPROGENyHALLMARKS+highCNagg+MethK5cluster{suffix}.pkl\"\n",
    "class params:\n",
    "        target_col = \"Cetuximab_Standard_3wks_cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis/Modeling\n",
    "## load all 'omics preprocessed datasets\n",
    "# K5 clusters encoded meth probes\n",
    "f = input.meth\n",
    "Meth = pd.read_csv(f, sep=\"\\t\", header=0, index_col=0)\n",
    "Meth = Meth[Meth.columns.drop(list(Meth.filter(regex='Cetuximab')))]\n",
    "# encoded expr data w/t progeny pathway scores + msdb hallmarks ssGSEA scores\n",
    "# processed through a colinearity + chi2 filter (drop the worst of each colinear pair of features)\n",
    "f = input.expr\n",
    "Expr = pd.read_csv(f, sep=\"\\t\", header=0, index_col=0)\n",
    "Expr = Expr[Expr.columns.drop(list(Expr.filter(regex='Cetuximab')))]\n",
    "Expr.columns = [c + \"_expr\" for c in Expr.columns]\n",
    "# raw expression data (variance-stabilised RNAseq)\n",
    "f = input.raw_expr\n",
    "raw_Expr = pd.read_csv(f, sep=\"\\t\", header=0, index_col=0)\n",
    "raw_Expr = raw_Expr[raw_Expr.columns.drop(list(raw_Expr.filter(regex='Cetuximab|ircc_id_short')))]\n",
    "raw_Expr.columns = [c + \"_rawExpr\" for c in raw_Expr.columns]\n",
    "# feature agglomeration CNV, input includes highGain features (> than 1 copy gained)\n",
    "f = input.cnv\n",
    "CNV = pd.read_csv(f, sep=\"\\t\", header=0, index_col=0)\n",
    "CNV = CNV[CNV.columns.drop(list(CNV.filter(regex='Cetuximab')))]\n",
    "CNV.columns = [c + \"_cnv\" for c in CNV.columns]\n",
    "# custom mut feature cross w/t top 20 features by chi2\n",
    "f = input.mut\n",
    "Mut = pd.read_csv(f, sep=\"\\t\", header=0, index_col=0)\n",
    "Mut = Mut[Mut.columns.drop(list(Mut.filter(regex='Cetuximab')))]\n",
    "Mut.columns = [c + \"_mut\" for c in Mut.columns]\n",
    "# add clinical data (custom encoding, filtering)\n",
    "f = input.clin\n",
    "Clin = pd.read_csv(f, sep=\"\\t\", header=0, index_col=0)\n",
    "Clin = Clin[Clin.columns.drop(list(Clin.filter(regex='Cetuximab')))]\n",
    "Clin.columns = [c + \"_clin\" for c in Clin.columns]\n",
    "# load drug response data\n",
    "f = input.response\n",
    "Y = pd.read_csv(f, sep=\"\\t\", index_col=1, header=0)\n",
    "# encode target var (binary responder/non-responder)\n",
    "target_col = params.target_col\n",
    "Y_class_dict={'PD':0,'OR+SD':1}\n",
    "Y[target_col] = Y[target_col].replace(Y_class_dict)\n",
    "\n",
    "# merge all feature blocks + response together\n",
    "df1 = pd.merge(Mut, CNV, right_index=True, left_index=True, how=\"outer\")\n",
    "df2 = pd.merge(Meth, Expr, right_index=True, left_index=True, how=\"outer\")\n",
    "all_df = pd.merge(df2, df1, right_index=True, left_index=True, how=\"outer\")\n",
    "all_df = pd.merge(all_df, Clin, right_index=True, left_index=True, how=\"outer\")\n",
    "all_df = pd.merge(all_df, raw_Expr, right_index=True, left_index=True, how=\"outer\")\n",
    "feature_col = all_df.columns.tolist()\n",
    "all_df = pd.merge(all_df, Y[target_col], right_index=True, left_index=True, how=\"right\")\n",
    "# drop duplicated instances (ircc_id) from index\n",
    "all_df = all_df[~all_df.index.duplicated(keep='first')]\n",
    "# fill sparse features with median imputation\n",
    "all_df[feature_col] = all_df[feature_col].\\\n",
    "    astype(float).apply(lambda col:col.fillna(col.median()))\n",
    "# force to numeric\n",
    "all_df = all_df.select_dtypes([np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "train_models = Y[Y.is_test == False].index.unique()\n",
    "test_models = Y[Y.is_test == True].index.unique()\n",
    "X_train = all_df.loc[train_models, feature_col]\n",
    "y_train  = all_df.loc[train_models, target_col]\n",
    "X_test = all_df.loc[test_models, feature_col]\n",
    "y_test = all_df.loc[test_models, target_col]\n",
    "#scale features separately\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train.values),\n",
    "          columns=X_train.columns, index=X_train.index)              \n",
    "X_test = pd.DataFrame(scaler.transform(X_test.values),\n",
    "          columns=X_test.columns, index=X_test.index)    \n",
    "# log train, test shape, dataset balance\n",
    "logfile = 'stacked_input.log'\n",
    "with open(logfile, \"w\") as log:\n",
    "    log.write(f\"There are {X_train.shape[0]} instances in the trainig set.\"+ '\\n')\n",
    "    log.write(f\"There are {X_test.shape[0]} instances in the test set.\"+ '\\n')\n",
    "    train_counts = y_train.value_counts()\n",
    "    test_counts = y_test.value_counts()  \n",
    "    log.write(f\"There are {train_counts.loc[0]} 'PD' instances and\\\n",
    "         {train_counts.loc[1]} 'SD+OR' instances in the training set.\"+ '\\n')\n",
    "    log.write(f\"There are {test_counts.loc[0]} 'PD' instances and\\\n",
    "         {test_counts.loc[1]} 'SD+OR' instances in the test set.\"+ '\\n')\n",
    "# get indeces for feature subsets, one per OMIC\n",
    "Meth_indeces = list(range(0, Meth.shape[1]))\n",
    "pos = len(Meth_indeces)\n",
    "Expr_indeces = list(range(Meth_indeces[-1]+1, pos + Expr.shape[1]))\n",
    "pos += len(Expr_indeces)\n",
    "Mut_indeces = list(range(Expr_indeces[-1]+1, pos + Mut.shape[1]))\n",
    "pos += len(Mut_indeces)\n",
    "CNV_indeces = list(range(Mut_indeces[-1]+1, pos + CNV.shape[1]))\n",
    "pos += len(CNV_indeces)\n",
    "Clin_indeces = list(range(CNV_indeces[-1]+1, pos + Clin.shape[1]))\n",
    "pos += len(Clin_indeces)\n",
    "rawExpr_indeces = list(range(Clin_indeces[-1]+1, pos + raw_Expr.shape[1]))\n",
    "# log n of features for each block\n",
    "with open(logfile, \"a\") as log:\n",
    "    log.write(f\"There are {X_train.shape[1]} total features.\"+ '\\n')\n",
    "    log.write(f\"There are {Meth.shape[1]} methylation features.\"+ '\\n')\n",
    "    log.write(f\"There are {Expr.shape[1]} Hallmarks, PROGENy expression features.\"+ '\\n')\n",
    "    log.write(f\"There are {raw_Expr.shape[1]} raw expression features.\"+ '\\n')\n",
    "    log.write(f\"There are {Mut.shape[1]} mutation features.\"+ '\\n')\n",
    "    log.write(f\"There are {CNV.shape[1]} copy number features.\"+ '\\n')\n",
    "    log.write(f\"There are {Clin.shape[1]} clinical features.\"+ '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ircc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRC1166LMX0A02001TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC1169LMX0A02001TUMD04000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC1241LMX0A01001TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0516LMX0B02003TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0578LMX0A02001TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0581LMX0A02003TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0610LMX0A02001TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0670LMX0A02001TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0680LMX0B02002TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0743LMX0A02003TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0783LMX0B01001TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0753LMX0A02004TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0729LMX0A02003TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0771LMX0B02001TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC1072LMX0A02002TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC1145LMX0A02001TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC1146LMX0A02001TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0504LMX0A02001TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0031LMX0A02203TUMD13000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0400LMX0A02001TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0166LMX0B02203TUMD02000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0307LMX0A02204TUMD04000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0356LMX0A02004TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0265LMX0B02204TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0019LMX0A02204TUMD05000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRC0062LMX0A02201TUMD02000</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [CRC1166LMX0A02001TUMD05000, CRC1169LMX0A02001TUMD04000, CRC1241LMX0A01001TUMD05000, CRC0516LMX0B02003TUMD05000, CRC0578LMX0A02001TUMD05000, CRC0581LMX0A02003TUMD05000, CRC0610LMX0A02001TUMD05000, CRC0670LMX0A02001TUMD05000, CRC0680LMX0B02002TUMD05000, CRC0743LMX0A02003TUMD05000, CRC0783LMX0B01001TUMD05000, CRC0753LMX0A02004TUMD05000, CRC0729LMX0A02003TUMD05000, CRC0771LMX0B02001TUMD05000, CRC1072LMX0A02002TUMD05000, CRC1145LMX0A02001TUMD05000, CRC1146LMX0A02001TUMD05000, CRC0504LMX0A02001TUMD05000, CRC0031LMX0A02203TUMD13000, CRC0400LMX0A02001TUMD05000, CRC0166LMX0B02203TUMD02000, CRC0307LMX0A02204TUMD04000, CRC0356LMX0A02004TUMD05000, CRC0265LMX0B02204TUMD05000, CRC0019LMX0A02204TUMD05000, CRC0062LMX0A02201TUMD02000]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[Expr_indeces].select_dtypes(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_variance(X, Y):\n",
    "\treturn pd.DataFrame(X).var()\n",
    "\n",
    "\n",
    "fitted_models = []\n",
    "# objective function for optuna\n",
    "def objective(trial):\n",
    "    # parameters to optimize\n",
    "    Meth_KNNlassifier__n_neighbors = trial.suggest_int(\"Meth_KNNlassifier__n_neighbors\", 5, 20, step=5)\n",
    "    Expr__chi2filterFscore__k = trial.suggest_int(\"Expr__chi2filterFscore__k\", 18, 30, step=2)\n",
    "    #rawExpr__Enet__l1_ratio = trial.suggest_float(\"rawExpr__Enet__l1_ratio\", 0.01, 0.99, step=.1)\n",
    "    #rawExpr__L1LR__C = trial.suggest_float(\"rawExpr__L1LR__C\",1, 50, step=5)\n",
    "    rawExpr__VariancePctl = trial.suggest_int(\"rawExpr__VariancePctl\", 5, 15, step=5)\n",
    "    Mut__chi2filterFscore__k = trial.suggest_int(\"Mut__chi2filterFscore__k\", 5, 20, step=5)\n",
    "    CNV__WardAgg__n_clusters = trial.suggest_int(\"CNV__WardAgg__n_clusters\", 50, 80, step=5)\n",
    "    CNV__chi2filterFscore__k = trial.suggest_int(\"CNV__chi2filterFscore__k\", 25, 45, step=5)\n",
    "    Clin__chi2filterFscore__k = trial.suggest_int(\"Clin__chi2filterFscore__k\", 4, 12, step=2)\n",
    "    meta__C = trial.suggest_float(\"meta__C\", 0.2, 0.9, step=.1)\n",
    "\n",
    "    # build stacked model pipeline\n",
    "    # pipeline to train a classifier on meth data alone\n",
    "    pipe_steps = [\n",
    "        (\"ColumnSelector\", ColumnSelector(cols=Meth_indeces)),\n",
    "        ('KNNlassifier', KNeighborsClassifier(n_neighbors=Meth_KNNlassifier__n_neighbors)),\n",
    "    ]\n",
    "    pipeMeth = Pipeline(pipe_steps)\n",
    "\n",
    "    # pipeline to train a classifier on Hallmarks, PROGENy scores (expression)\n",
    "    pipe_steps = [\n",
    "        (\"ColumnSelector\", ColumnSelector(cols=Expr_indeces)),\n",
    "        (\"chi2filterFscore\", SelectKBest(chi2, k=15)), \n",
    "        ('RFClassifier', RandomForestClassifier()),\n",
    "    ]\n",
    "    pipeExpr = Pipeline(pipe_steps)\n",
    "\n",
    "    # build the L1 logistic selector for expression features\n",
    "    L1LR = LogisticRegression(\n",
    "        C=.3,\n",
    "        penalty='l1',\n",
    "        solver='saga')\n",
    "    L1Selector = SelectFromModel(estimator=L1LR, max_features=25)\n",
    "    elasticNetClassifier = LogisticRegression(\n",
    "        penalty='elasticnet',\n",
    "        l1_ratio=.3,\n",
    "        random_state=13,\n",
    "        solver='saga')\n",
    "    Expr_selector = SelectPercentile(calc_variance, percentile=5)\n",
    "    pipe_steps = [\n",
    "        (\"ColumnSelector\", ColumnSelector(cols=rawExpr_indeces)),\n",
    "        (\"VarianceFilter\", Expr_selector), \n",
    "        (\"L1Selector\", L1Selector), \n",
    "        ('elasticNetClassifier', elasticNetClassifier),\n",
    "    ]\n",
    "    pipeRawExpr = Pipeline(pipe_steps)\n",
    "\n",
    "    # pipeline to train a classifier on mutation data alone\n",
    "    pipe_steps = [\n",
    "        (\"ColumnSelector\", ColumnSelector(cols=Mut_indeces)),\n",
    "        (\"chi2filterFscore\", SelectKBest(chi2, k=Mut__chi2filterFscore__k)), # univariate filter on chi2 stat\n",
    "        ('RFClassifier', RandomForestClassifier()),\n",
    "    ]\n",
    "    pipeMut = Pipeline(pipe_steps)\n",
    "\n",
    "    # pipeline to train a classifier on CNV data alone\n",
    "    pipe_steps = [\n",
    "        (\"ColumnSelector\", ColumnSelector(cols=CNV_indeces)),\n",
    "        # remove samples which have the same val in 5% or more samples\n",
    "        (\"VarianceFilter\", VarianceThreshold(threshold=(.75 * (1 - .75)))),\n",
    "        (\"WardAgg\", FeatureAgglomeration(n_clusters=CNV__WardAgg__n_clusters)), # Ward feature agglomeration by mean\n",
    "        (\"chi2filterFscore\", SelectKBest(chi2, CNV__chi2filterFscore__k)), \n",
    "        ('RFClassifier', RandomForestClassifier()),\n",
    "    ]\n",
    "    pipeCNV = Pipeline(pipe_steps)\n",
    "\n",
    "    # pipeline to train a classifier on clinical/patient data alone\n",
    "    pipe_steps = [\n",
    "        (\"ColumnSelector\", ColumnSelector(cols=Clin_indeces)),\n",
    "        (\"chi2filterFscore\", SelectKBest(chi2, k=Clin__chi2filterFscore__k)), \n",
    "        ('RFClassifier', RandomForestClassifier()),\n",
    "    ]\n",
    "    pipeClin = Pipeline(pipe_steps)\n",
    "\n",
    "\n",
    "    # build the meta classifier\n",
    "    skf = StratifiedKFold(n_splits=4,shuffle=True,random_state=13)\n",
    "    sclf = StackingCVClassifier(classifiers=[\n",
    "                                            pipeMeth, \n",
    "                                            pipeExpr,\n",
    "                                            #pipeRawExpr, \n",
    "                                            pipeMut, \n",
    "                                            pipeCNV, \n",
    "                                            pipeClin\n",
    "                                            ], \n",
    "                            cv=skf,\n",
    "                            n_jobs=-1,\n",
    "                            shuffle=True, \n",
    "                            random_state=13, \n",
    "                            verbose=0,\n",
    "                            #use_probas=True,\n",
    "                            #average_probas=False,\n",
    "                            #use_features_in_secondary=True,\n",
    "                            meta_classifier=LogisticRegression(penalty='l2', \n",
    "                            class_weight='balanced'))\n",
    "\n",
    "    # fit on train, test return ROC AUC\n",
    "    sclf = sclf.fit(X_train, y_train)\n",
    "    #train_auc = roc_auc_score(y_train, sclf.predict(X_train))\n",
    "    train_auc = cross_val_score(sclf, X_train, y_train, scoring='roc_auc', n_jobs=-1, cv=2).mean()\n",
    "    test_auc = roc_auc_score(y_test, sclf.predict(X_test))\n",
    "    fitted_models.append([test_auc, train_auc, sclf])\n",
    "    return train_auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-bb8a84b4f82e>:1: ExperimentalWarning: MLflowCallback is experimental (supported from v1.4.0). The interface can change in the future.\n",
      "  mlflow_cb = MLflowCallback(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlflow_cb = MLflowCallback(\n",
    "    tracking_uri='mlruns',\n",
    "    metric_name='ROC AUC'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 10:29:27,591]\u001b[0m A new study created in memory with name: Cetuximab_sensitivity_prediction\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "CS_study = optuna.create_study(\n",
    "    study_name='Cetuximab_sensitivity_prediction',\n",
    "    direction='maximize',\n",
    "    pruner=optuna.pruners.HyperbandPruner(max_resource=\"auto\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass k=45 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/joblib/parallel.py:546: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/joblib/parallel.py:546: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/joblib/parallel.py:546: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/joblib/parallel.py:546: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/joblib/parallel.py:546: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/joblib/parallel.py:546: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/joblib/parallel.py:546: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/joblib/parallel.py:546: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/joblib/parallel.py:546: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/joblib/parallel.py:546: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/joblib/parallel.py:546: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/joblib/parallel.py:546: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/ensemble/_base.py:178: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "\u001b[32m[I 2022-01-25 10:29:34,624]\u001b[0m Trial 0 finished with value: 0.8125582852480037 and parameters: {'Meth_KNNlassifier__n_neighbors': 5, 'Expr__chi2filterFscore__k': 28, 'rawExpr__VariancePctl': 15, 'Mut__chi2filterFscore__k': 20, 'CNV__WardAgg__n_clusters': 50, 'CNV__chi2filterFscore__k': 45, 'Clin__chi2filterFscore__k': 10, 'meta__C': 0.5}. Best is trial 0 with value: 0.8125582852480037.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "CS_study.optimize(objective, n_trials=100, callbacks=[mlflow_cb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Show graphs and stats here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CS_study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CS_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = optuna.visualization.plot_optimization_history(CS_study)\n",
    "fw1 = go.FigureWidget(fig1)\n",
    "fw1.update_layout(width=610, margin=dict(r=250))\n",
    "\n",
    "fig2 = optuna.visualization.plot_param_importances(CS_study)\n",
    "fw2 = go.FigureWidget(fig2)\n",
    "fw2.update_layout(margin=dict(r=100))\n",
    "\n",
    "fig_subplots=ipyw.HBox([fw2, fw1])\n",
    "fig_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_df = pd.DataFrame(fitted_models, \n",
    "\tcolumns=['test_auc', 'train_auc', 'fitted_model_obj']).\\\n",
    "\t\tsort_values('train_auc', ascending=False)\n",
    "best_model = best_model_df.iloc[0].fitted_model_obj\n",
    "best_model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = best_model\n",
    "# assess best classifier performance on test set\n",
    "test_score = classifier.score(X_test, y_test)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(f'Accuracy on test set: {test_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification report on test set\n",
    "print(classification_report(y_test, y_pred, target_names=['PD', 'SD-OR']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(classifier, X_test, y_test,\n",
    "    display_labels=['PD', 'SD-OR'],\n",
    "    cmap=plt.cm.Blues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triple_neg_CM = confusion_matrix(y_test, X_test['KRAS_BRAF_NRAS_triple_neg_mut'])\n",
    "FP = triple_neg_CM.sum(axis=0) - np.diag(triple_neg_CM)  \n",
    "FN = triple_neg_CM.sum(axis=1) - np.diag(triple_neg_CM)\n",
    "TP = np.diag(triple_neg_CM)\n",
    "TN = triple_neg_CM.sum() - (FP + FN + TP)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "tripleNeg_TPR = TP/(TP+FN)\n",
    "# Fall out or false positive rate\n",
    "tripleNeg_FPR = FP/(FP+TN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the marginal probability that the given sample has the label in question\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_test_predict_proba = classifier.predict_proba(X_test)\n",
    "fp_rates, tp_rates, _ = roc_curve(y_test,y_test_predict_proba[:,1])\n",
    "roc_auc = auc(fp_rates, tp_rates)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "plt.plot(fp_rates, tp_rates, color='green',\n",
    "            lw=1.5, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], lw=1, linestyle='--', color='grey')\n",
    "\n",
    "#plot decision point:\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = [i for i in cm.ravel()]\n",
    "plt.plot(fp/(fp+tn), \n",
    "\ttp/(tp+fn), \n",
    "\tmarker='o',\n",
    "\tcolor='darkgreen', \n",
    "\tmarkersize=8, \n",
    "\tlabel='Stacked decision point')\n",
    "\n",
    "# add triple negative baseline\n",
    "#ax.axvline(tripleNeg_FPR[1], ls=':', c='k', \n",
    "#        label='KRAS-BRAF-NRAS tripleNeg median')\n",
    "plt.plot(tripleNeg_FPR[1], \n",
    "\ttripleNeg_TPR[1], \n",
    "\tmarker='o',\n",
    "\tc='violet', \n",
    "\tmarkersize=8,\n",
    "\tzorder=10,\n",
    "\tlabel='KRAS-BRAF-NRAS tripleNeg decision point')\n",
    "#ax.axhline(tripleNeg_TPR[1], ls=':', c='k', \n",
    "#        label='KRAS-BRAF-NRAS tripleNeg median')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', size=13)\n",
    "plt.ylabel('True Positive Rate', size=13)\n",
    "plt.title(f'ROC Curve on PDX test set (N={X_test.shape[0]})', size=15)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 10})\n",
    "plt.subplots_adjust(wspace=.3)\n",
    "\n",
    "\n",
    "plt.savefig(\"bestStackedCVClassifier_vs_TripleNeg_AUC.pdf\", \n",
    "                format='pdf', dpi=720, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and Next Steps\n",
    "Summarize findings here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
