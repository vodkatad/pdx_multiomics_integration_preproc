{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "State notebook purpose here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Import libraries and write settings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Options for pandas\n",
    "# No warnings about setting value on copy of slice\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 600\n",
    "pd.options.display.max_rows = 30\n",
    "\n",
    "# autoML\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from ConfigSpace.configuration_space import Configuration\n",
    "import autosklearn.classification\n",
    "import PipelineProfiler\n",
    "\n",
    "\n",
    "# scalers\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# models\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "# xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# processing\n",
    "from sklearn.preprocessing import label_binarize, PolynomialFeatures\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn import model_selection\n",
    "\n",
    "# dimensionality reduction, clustering\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering, MeanShift, DBSCAN\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import umap\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold, chi2\n",
    "\n",
    "# benchmark\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_curve, multilabel_confusion_matrix, auc, matthews_corrcoef, roc_auc_score, accuracy_score, classification_report, confusion_matrix, plot_confusion_matrix\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "import pickle\n",
    "import vaex\n",
    "\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "\n",
    "# autoreload extension\n",
    "if 'autoreload' not in ipython.extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "# Set default font size\n",
    "plt.rcParams['font.size'] = 24\n",
    "import seaborn as sb\n",
    "# Set default font size\n",
    "sb.set(font_scale = .8)\n",
    "custom_style = {'axes.labelcolor': 'black',\n",
    "                'xtick.color': 'black',\n",
    "                'ytick.color': 'black'}\n",
    "sb.set_style(\"white\", rc=custom_style)\n",
    "\n",
    "\n",
    "# Interactive Visualizations\n",
    "# import plotly.plotly as py\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.offline import iplot, init_notebook_mode\n",
    "# init_notebook_mode(connected=True)\n",
    "\n",
    "# import cufflinks as cf\n",
    "# cf.go_offline(connected=True)\n",
    "# icf.set_config_file(theme='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis/Modeling\n",
    "Do work here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         1  2  3  4  5\n",
       "CRC0238  1  0  0  0  0\n",
       "CRC0291  1  0  0  0  0\n",
       "CRC0223  0  0  1  0  0\n",
       "CRC0313  1  0  0  0  0\n",
       "CRC0340  1  0  0  0  0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>CRC0238</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>CRC0291</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>CRC0223</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>CRC0313</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>CRC0340</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "# load pre-computed meth cluster labels\n",
    "# TODO re compute on train set only to prevent info leaks\n",
    "f = \"data/methylation/k5_samples-clusters_division.tsv\"\n",
    "k5_clusters = pd.read_csv(f, sep=\"\\t\", header=0)\n",
    "# convert index to CRC id short\n",
    "k5_clusters.index = [c[:-3] for c in k5_clusters.index.tolist()]\n",
    "# encode cluster labels as binary features\n",
    "k5_clusters = pd.get_dummies(k5_clusters.cluster)\n",
    "k5_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                            Cetuximab_Standard_3wks_cat  1  2  3  4  5\n",
       "ircc_id                                                               \n",
       "CRC0442LMX0A02004TUMD05000                            1  0  0  0  1  0\n",
       "CRC0580LMX0B02002TUMD05000                            0  0  0  0  0  1\n",
       "CRC0574LMX0A02001TUMD05000                            1  0  0  0  1  0\n",
       "CRC0616LMX0A02001TUMD05000                            0  0  0  0  0  1\n",
       "CRC0718LMX0A02004TUMD05000                            1  0  0  0  1  0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cetuximab_Standard_3wks_cat</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n    <tr>\n      <th>ircc_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>CRC0442LMX0A02004TUMD05000</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>CRC0580LMX0B02002TUMD05000</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>CRC0574LMX0A02001TUMD05000</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>CRC0616LMX0A02001TUMD05000</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>CRC0718LMX0A02004TUMD05000</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "# load sample id conversion table, drug response data\n",
    "drug_response_data = pd.read_csv(\"tables/DrugResponse_LMXfirslevel_trainTest.csv\", sep=\"\\t\")\n",
    "        \n",
    "features_clean_df = pd.merge(drug_response_data[[\n",
    "                            \"Cetuximab_Standard_3wks_cat\", \"ircc_id_short\", \"ircc_id\", \"is_test\"]],\n",
    "                            k5_clusters,\n",
    "                            left_on=\"ircc_id_short\",\n",
    "                            right_index=True)\n",
    "\n",
    "# encode target\n",
    "Y_class_dict={'PD':0,'SD':1, 'OR':1}\n",
    "features_clean_df['Cetuximab_Standard_3wks_cat'] =  features_clean_df['Cetuximab_Standard_3wks_cat'].replace(Y_class_dict)      \n",
    "               \n",
    "train_models = features_clean_df[features_clean_df.is_test == False].ircc_id.unique()\n",
    "test_models = features_clean_df[features_clean_df.is_test == True].ircc_id.unique()\n",
    "features_clean_df = features_clean_df.drop([\"is_test\", \"ircc_id_short\"], axis=1).set_index(\"ircc_id\")\n",
    "\n",
    "features_clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_matrix = features_clean_df\n",
    "input_matrix.index = input_matrix.index.values\n",
    "target_col = \"Cetuximab_Standard_3wks_cat\"\n",
    "features_col = np.array([c for c in input_matrix.columns if c != target_col])\n",
    "# save processed features\n",
    "features_clean_df[features_col].to_csv('tables/preprocessed_features/methK5Clusters.tsv',\n",
    "                                          sep='\\t')\n",
    "\n",
    "# train-test split\n",
    "X_train = input_matrix.loc[train_models, features_col].values\n",
    "y_train  = input_matrix.loc[train_models, target_col].values\n",
    "X_test = input_matrix.loc[test_models, features_col].values\n",
    "y_test = input_matrix.loc[test_models, target_col].values\n",
    "\n",
    "# scale features\n",
    "X_train = MinMaxScaler().fit_transform(X_train)\n",
    "X_test = MinMaxScaler().fit_transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(180, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(58, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "X_train.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[16:48:10] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(LogisticRegression(), 0.5517241379310345),\n",
       " (LinearSVC(), 0.5517241379310345),\n",
       " (KNeighborsClassifier(), 0.6379310344827587),\n",
       " (RandomForestClassifier(), 0.5517241379310345),\n",
       " (XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                importance_type='gain', interaction_constraints='',\n",
       "                learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "                min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "                n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "                reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "                tree_method='exact', validate_parameters=1, verbosity=None),\n",
       "  0.5517241379310345)]"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# basic classifier accuracy test\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "svm = LinearSVC().fit(X_train, y_train)\n",
    "knc = KNeighborsClassifier().fit(X_train, y_train)\n",
    "rfc = RandomForestClassifier().fit(X_train, y_train)\n",
    "xgc = XGBClassifier().fit(X_train, y_train)\n",
    "[(model, accuracy_score(y_test, model.predict(X_test))) for model in [lr, svm, knc, rfc, xgc]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline to train a classifier on meth data alone\n",
    "pipe_steps = [\n",
    "    (\"VarianceFilter\", VarianceThreshold(threshold=0)), # drop features with 0 variance\n",
    "    ('KNNlassifier', KNeighborsClassifier().fit(X_train, y_train)),\n",
    "]\n",
    "\n",
    "pipeMeth = Pipeline(pipe_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_grid = {\n",
    "          'KNNlassifier__n_neighbors' : list(range(1,30)),\n",
    "          'KNNlassifier__p' : [1, 2, 3, 4, 5],\n",
    "          #'RFClassifier__max_features' : np.linspace(.01, .8, 5, endpoint=True),\n",
    "          #'RFClassifier__min_samples_split' :  np.linspace(.01, .5, 5, endpoint=True),\n",
    "          }\n",
    "\n",
    "# Set up the random search with 4-fold stratified cross validation\n",
    "skf = StratifiedKFold(n_splits=4,shuffle=True,random_state=42)\n",
    "grid = GridSearchCV(estimator=pipeMeth, \n",
    "                    param_grid=hyperparameter_grid, \n",
    "                    scoring=\"accuracy\",\n",
    "                    n_jobs=-1,\n",
    "                    cv=skf,\n",
    "                    refit=True,\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "V] END ....KNNlassifier__n_neighbors=26, KNNlassifier__p=2; total time=   0.0s[CV] END ....KNNlassifier__n_neighbors=28, KNNlassifier__p=1; total time=   0.0s\n",
      "\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=28, KNNlassifier__p=2; total time=   0.0s\n",
      "[CV] END ....KNNlassifier__n_neighbors=26, KNNlassifier__p=3; total time=   0.0s/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "\n",
      "[CV] END ....KNNlassifier__n_neighbors=28, KNNlassifier__p=2; total time=   0.0s/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=26, KNNlassifier__p=3; total time=   0.0s\n",
      "[CV] END ....KNNlassifier__n_neighbors=28, KNNlassifier__p=2; total time=   0.0s/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=26, KNNlassifier__p=3; total time=   0.0s\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=28, KNNlassifier__p=2; total time=   0.0s\n",
      "[CV] END ....KNNlassifier__n_neighbors=26, KNNlassifier__p=3; total time=   0.0s\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=26, KNNlassifier__p=4; total time=   0.0s[CV] END ....KNNlassifier__n_neighbors=28, KNNlassifier__p=3; total time=   0.0s\n",
      "\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=26, KNNlassifier__p=4; total time=   0.0s\n",
      "[CV] END ....KNNlassifier__n_neighbors=28, KNNlassifier__p=3; total time=   0.0s\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=26, KNNlassifier__p=4; total time=   0.0s\n",
      "[CV] END ....KNNlassifier__n_neighbors=28, KNNlassifier__p=3; total time=   0.0s/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=26, KNNlassifier__p=4; total time=   0.0s\n",
      "[CV] END ....KNNlassifier__n_neighbors=28, KNNlassifier__p=3; total time=   0.0s/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "\n",
      "[CV] END ....KNNlassifier__n_neighbors=26, KNNlassifier__p=5; total time=   0.0s\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=26, KNNlassifier__p=5; total time=   0.0s[CV] END ....KNNlassifier__n_neighbors=28, KNNlassifier__p=4; total time=   0.0s\n",
      "\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=26, KNNlassifier__p=5; total time=   0.0s[CV] END ....KNNlassifier__n_neighbors=28, KNNlassifier__p=4; total time=   0.0s\n",
      "\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=26, KNNlassifier__p=5; total time=   0.0s[CV] END ....KNNlassifier__n_neighbors=28, KNNlassifier__p=4; total time=   0.0s\n",
      "\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=27, KNNlassifier__p=1; total time=   0.0s[CV] END ....KNNlassifier__n_neighbors=28, KNNlassifier__p=4; total time=   0.0s\n",
      "\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=27, KNNlassifier__p=1; total time=   0.0s\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=28, KNNlassifier__p=5; total time=   0.0s\n",
      "[CV] END ....KNNlassifier__n_neighbors=27, KNNlassifier__p=1; total time=   0.0s\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=27, KNNlassifier__p=1; total time=   0.0s[CV] END ....KNNlassifier__n_neighbors=28, KNNlassifier__p=5; total time=   0.0s\n",
      "\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=27, KNNlassifier__p=2; total time=   0.0s\n",
      "[CV] END ....KNNlassifier__n_neighbors=28, KNNlassifier__p=5; total time=   0.0s/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=27, KNNlassifier__p=2; total time=   0.0s[CV] END ....KNNlassifier__n_neighbors=28, KNNlassifier__p=5; total time=   0.0s\n",
      "\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=1; total time=   0.0s[CV] END ....KNNlassifier__n_neighbors=27, KNNlassifier__p=2; total time=   0.0s\n",
      "\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=27, KNNlassifier__p=2; total time=   0.0s[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=1; total time=   0.0s\n",
      "\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=1; total time=   0.0s\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=27, KNNlassifier__p=3; total time=   0.0s\n",
      "[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=1; total time=   0.0s/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "\n",
      "[CV] END ....KNNlassifier__n_neighbors=27, KNNlassifier__p=3; total time=   0.0s\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=2; total time=   0.0s[CV] END ....KNNlassifier__n_neighbors=27, KNNlassifier__p=3; total time=   0.0s\n",
      "\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=27, KNNlassifier__p=3; total time=   0.0s/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=2; total time=   0.0s\n",
      "\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=2; total time=   0.0s\n",
      "[CV] END ....KNNlassifier__n_neighbors=27, KNNlassifier__p=4; total time=   0.0s/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "\n",
      "[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=2; total time=   0.0s/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=27, KNNlassifier__p=4; total time=   0.0s[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=3; total time=   0.0s\n",
      "\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=3; total time=   0.0s\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=3; total time=   0.0s\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=3; total time=   0.0s\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=4; total time=   0.0s\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=4; total time=   0.0s\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=4; total time=   0.0s\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=4; total time=   0.0s\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=5; total time=   0.0s\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=5; total time=   0.0s\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=5; total time=   0.0s\n",
      "/home/umberto.perron/anaconda3/envs/PDx_py_combio02/lib/python3.8/site-packages/sklearn/neighbors/_base.py:686: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  n_jobs = effective_n_jobs(self.n_jobs)\n",
      "[CV] END ....KNNlassifier__n_neighbors=29, KNNlassifier__p=5; total time=   0.0s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('VarianceFilter',\n",
       "                                        VarianceThreshold(threshold=0)),\n",
       "                                       ('KNNlassifier',\n",
       "                                        KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'KNNlassifier__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                                                       9, 10, 11, 12, 13, 14,\n",
       "                                                       15, 16, 17, 18, 19, 20,\n",
       "                                                       21, 22, 23, 24, 25, 26,\n",
       "                                                       27, 28, 29],\n",
       "                         'KNNlassifier__p': [1, 2, 3, 4, 5]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.661 +/- 0.00 {'KNNlassifier__n_neighbors': 1, 'KNNlassifier__p': 1}\n0.661 +/- 0.00 {'KNNlassifier__n_neighbors': 1, 'KNNlassifier__p': 2}\n0.661 +/- 0.00 {'KNNlassifier__n_neighbors': 1, 'KNNlassifier__p': 3}\n0.661 +/- 0.00 {'KNNlassifier__n_neighbors': 1, 'KNNlassifier__p': 4}\n0.661 +/- 0.00 {'KNNlassifier__n_neighbors': 1, 'KNNlassifier__p': 5}\n0.622 +/- 0.02 {'KNNlassifier__n_neighbors': 2, 'KNNlassifier__p': 1}\n0.622 +/- 0.02 {'KNNlassifier__n_neighbors': 2, 'KNNlassifier__p': 2}\n0.622 +/- 0.02 {'KNNlassifier__n_neighbors': 2, 'KNNlassifier__p': 3}\n0.622 +/- 0.02 {'KNNlassifier__n_neighbors': 2, 'KNNlassifier__p': 4}\n0.622 +/- 0.02 {'KNNlassifier__n_neighbors': 2, 'KNNlassifier__p': 5}\n0.644 +/- 0.02 {'KNNlassifier__n_neighbors': 3, 'KNNlassifier__p': 1}\n0.644 +/- 0.02 {'KNNlassifier__n_neighbors': 3, 'KNNlassifier__p': 2}\n0.644 +/- 0.02 {'KNNlassifier__n_neighbors': 3, 'KNNlassifier__p': 3}\n0.644 +/- 0.02 {'KNNlassifier__n_neighbors': 3, 'KNNlassifier__p': 4}\n0.644 +/- 0.02 {'KNNlassifier__n_neighbors': 3, 'KNNlassifier__p': 5}\n0.633 +/- 0.02 {'KNNlassifier__n_neighbors': 4, 'KNNlassifier__p': 1}\n0.633 +/- 0.02 {'KNNlassifier__n_neighbors': 4, 'KNNlassifier__p': 2}\n0.633 +/- 0.02 {'KNNlassifier__n_neighbors': 4, 'KNNlassifier__p': 3}\n0.633 +/- 0.02 {'KNNlassifier__n_neighbors': 4, 'KNNlassifier__p': 4}\n0.633 +/- 0.02 {'KNNlassifier__n_neighbors': 4, 'KNNlassifier__p': 5}\n0.650 +/- 0.02 {'KNNlassifier__n_neighbors': 5, 'KNNlassifier__p': 1}\n0.650 +/- 0.02 {'KNNlassifier__n_neighbors': 5, 'KNNlassifier__p': 2}\n0.650 +/- 0.02 {'KNNlassifier__n_neighbors': 5, 'KNNlassifier__p': 3}\n0.650 +/- 0.02 {'KNNlassifier__n_neighbors': 5, 'KNNlassifier__p': 4}\n0.650 +/- 0.02 {'KNNlassifier__n_neighbors': 5, 'KNNlassifier__p': 5}\n0.628 +/- 0.02 {'KNNlassifier__n_neighbors': 6, 'KNNlassifier__p': 1}\n0.628 +/- 0.02 {'KNNlassifier__n_neighbors': 6, 'KNNlassifier__p': 2}\n0.628 +/- 0.02 {'KNNlassifier__n_neighbors': 6, 'KNNlassifier__p': 3}\n0.628 +/- 0.02 {'KNNlassifier__n_neighbors': 6, 'KNNlassifier__p': 4}\n0.628 +/- 0.02 {'KNNlassifier__n_neighbors': 6, 'KNNlassifier__p': 5}\n0.628 +/- 0.02 {'KNNlassifier__n_neighbors': 7, 'KNNlassifier__p': 1}\n0.628 +/- 0.02 {'KNNlassifier__n_neighbors': 7, 'KNNlassifier__p': 2}\n0.628 +/- 0.02 {'KNNlassifier__n_neighbors': 7, 'KNNlassifier__p': 3}\n0.628 +/- 0.02 {'KNNlassifier__n_neighbors': 7, 'KNNlassifier__p': 4}\n0.628 +/- 0.02 {'KNNlassifier__n_neighbors': 7, 'KNNlassifier__p': 5}\n0.622 +/- 0.02 {'KNNlassifier__n_neighbors': 8, 'KNNlassifier__p': 1}\n0.622 +/- 0.02 {'KNNlassifier__n_neighbors': 8, 'KNNlassifier__p': 2}\n0.622 +/- 0.02 {'KNNlassifier__n_neighbors': 8, 'KNNlassifier__p': 3}\n0.622 +/- 0.02 {'KNNlassifier__n_neighbors': 8, 'KNNlassifier__p': 4}\n0.622 +/- 0.02 {'KNNlassifier__n_neighbors': 8, 'KNNlassifier__p': 5}\n0.656 +/- 0.03 {'KNNlassifier__n_neighbors': 9, 'KNNlassifier__p': 1}\n0.656 +/- 0.03 {'KNNlassifier__n_neighbors': 9, 'KNNlassifier__p': 2}\n0.656 +/- 0.03 {'KNNlassifier__n_neighbors': 9, 'KNNlassifier__p': 3}\n0.656 +/- 0.03 {'KNNlassifier__n_neighbors': 9, 'KNNlassifier__p': 4}\n0.656 +/- 0.03 {'KNNlassifier__n_neighbors': 9, 'KNNlassifier__p': 5}\n0.622 +/- 0.02 {'KNNlassifier__n_neighbors': 10, 'KNNlassifier__p': 1}\n0.622 +/- 0.02 {'KNNlassifier__n_neighbors': 10, 'KNNlassifier__p': 2}\n0.622 +/- 0.02 {'KNNlassifier__n_neighbors': 10, 'KNNlassifier__p': 3}\n0.622 +/- 0.02 {'KNNlassifier__n_neighbors': 10, 'KNNlassifier__p': 4}\n0.622 +/- 0.02 {'KNNlassifier__n_neighbors': 10, 'KNNlassifier__p': 5}\n0.672 +/- 0.02 {'KNNlassifier__n_neighbors': 11, 'KNNlassifier__p': 1}\n0.672 +/- 0.02 {'KNNlassifier__n_neighbors': 11, 'KNNlassifier__p': 2}\n0.672 +/- 0.02 {'KNNlassifier__n_neighbors': 11, 'KNNlassifier__p': 3}\n0.672 +/- 0.02 {'KNNlassifier__n_neighbors': 11, 'KNNlassifier__p': 4}\n0.672 +/- 0.02 {'KNNlassifier__n_neighbors': 11, 'KNNlassifier__p': 5}\n0.672 +/- 0.02 {'KNNlassifier__n_neighbors': 12, 'KNNlassifier__p': 1}\n0.672 +/- 0.02 {'KNNlassifier__n_neighbors': 12, 'KNNlassifier__p': 2}\n0.672 +/- 0.02 {'KNNlassifier__n_neighbors': 12, 'KNNlassifier__p': 3}\n0.672 +/- 0.02 {'KNNlassifier__n_neighbors': 12, 'KNNlassifier__p': 4}\n0.672 +/- 0.02 {'KNNlassifier__n_neighbors': 12, 'KNNlassifier__p': 5}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 13, 'KNNlassifier__p': 1}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 13, 'KNNlassifier__p': 2}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 13, 'KNNlassifier__p': 3}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 13, 'KNNlassifier__p': 4}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 13, 'KNNlassifier__p': 5}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 14, 'KNNlassifier__p': 1}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 14, 'KNNlassifier__p': 2}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 14, 'KNNlassifier__p': 3}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 14, 'KNNlassifier__p': 4}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 14, 'KNNlassifier__p': 5}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 15, 'KNNlassifier__p': 1}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 15, 'KNNlassifier__p': 2}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 15, 'KNNlassifier__p': 3}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 15, 'KNNlassifier__p': 4}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 15, 'KNNlassifier__p': 5}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 16, 'KNNlassifier__p': 1}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 16, 'KNNlassifier__p': 2}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 16, 'KNNlassifier__p': 3}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 16, 'KNNlassifier__p': 4}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 16, 'KNNlassifier__p': 5}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 17, 'KNNlassifier__p': 1}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 17, 'KNNlassifier__p': 2}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 17, 'KNNlassifier__p': 3}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 17, 'KNNlassifier__p': 4}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 17, 'KNNlassifier__p': 5}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 18, 'KNNlassifier__p': 1}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 18, 'KNNlassifier__p': 2}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 18, 'KNNlassifier__p': 3}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 18, 'KNNlassifier__p': 4}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 18, 'KNNlassifier__p': 5}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 19, 'KNNlassifier__p': 1}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 19, 'KNNlassifier__p': 2}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 19, 'KNNlassifier__p': 3}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 19, 'KNNlassifier__p': 4}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 19, 'KNNlassifier__p': 5}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 20, 'KNNlassifier__p': 1}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 20, 'KNNlassifier__p': 2}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 20, 'KNNlassifier__p': 3}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 20, 'KNNlassifier__p': 4}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 20, 'KNNlassifier__p': 5}\n0.678 +/- 0.03 {'KNNlassifier__n_neighbors': 21, 'KNNlassifier__p': 1}\n0.678 +/- 0.03 {'KNNlassifier__n_neighbors': 21, 'KNNlassifier__p': 2}\n0.678 +/- 0.03 {'KNNlassifier__n_neighbors': 21, 'KNNlassifier__p': 3}\n0.678 +/- 0.03 {'KNNlassifier__n_neighbors': 21, 'KNNlassifier__p': 4}\n0.678 +/- 0.03 {'KNNlassifier__n_neighbors': 21, 'KNNlassifier__p': 5}\n0.678 +/- 0.03 {'KNNlassifier__n_neighbors': 22, 'KNNlassifier__p': 1}\n0.678 +/- 0.03 {'KNNlassifier__n_neighbors': 22, 'KNNlassifier__p': 2}\n0.678 +/- 0.03 {'KNNlassifier__n_neighbors': 22, 'KNNlassifier__p': 3}\n0.678 +/- 0.03 {'KNNlassifier__n_neighbors': 22, 'KNNlassifier__p': 4}\n0.678 +/- 0.03 {'KNNlassifier__n_neighbors': 22, 'KNNlassifier__p': 5}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 23, 'KNNlassifier__p': 1}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 23, 'KNNlassifier__p': 2}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 23, 'KNNlassifier__p': 3}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 23, 'KNNlassifier__p': 4}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 23, 'KNNlassifier__p': 5}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 24, 'KNNlassifier__p': 1}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 24, 'KNNlassifier__p': 2}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 24, 'KNNlassifier__p': 3}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 24, 'KNNlassifier__p': 4}\n0.683 +/- 0.02 {'KNNlassifier__n_neighbors': 24, 'KNNlassifier__p': 5}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 25, 'KNNlassifier__p': 1}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 25, 'KNNlassifier__p': 2}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 25, 'KNNlassifier__p': 3}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 25, 'KNNlassifier__p': 4}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 25, 'KNNlassifier__p': 5}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 26, 'KNNlassifier__p': 1}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 26, 'KNNlassifier__p': 2}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 26, 'KNNlassifier__p': 3}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 26, 'KNNlassifier__p': 4}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 26, 'KNNlassifier__p': 5}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 27, 'KNNlassifier__p': 1}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 27, 'KNNlassifier__p': 2}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 27, 'KNNlassifier__p': 3}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 27, 'KNNlassifier__p': 4}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 27, 'KNNlassifier__p': 5}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 28, 'KNNlassifier__p': 1}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 28, 'KNNlassifier__p': 2}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 28, 'KNNlassifier__p': 3}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 28, 'KNNlassifier__p': 4}\n0.672 +/- 0.03 {'KNNlassifier__n_neighbors': 28, 'KNNlassifier__p': 5}\n0.667 +/- 0.03 {'KNNlassifier__n_neighbors': 29, 'KNNlassifier__p': 1}\n0.667 +/- 0.03 {'KNNlassifier__n_neighbors': 29, 'KNNlassifier__p': 2}\n0.667 +/- 0.03 {'KNNlassifier__n_neighbors': 29, 'KNNlassifier__p': 3}\n0.667 +/- 0.03 {'KNNlassifier__n_neighbors': 29, 'KNNlassifier__p': 4}\n0.667 +/- 0.03 {'KNNlassifier__n_neighbors': 29, 'KNNlassifier__p': 5}\nBest parameters: {'KNNlassifier__n_neighbors': 13, 'KNNlassifier__p': 1}\nAccuracy on train: 0.68\nAccuracy on test set: 0.638\n              precision    recall  f1-score   support\n\n          PD       0.68      0.70      0.69        33\n       SD-OR       0.58      0.56      0.57        25\n\n    accuracy                           0.64        58\n   macro avg       0.63      0.63      0.63        58\nweighted avg       0.64      0.64      0.64        58\n\n"
     ]
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "\n",
    "cv_keys = ('mean_test_score', 'std_test_score', 'params')\n",
    "\n",
    "for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    print(\"%0.3f +/- %0.2f %r\"\n",
    "          % (grid.cv_results_[cv_keys[0]][r],\n",
    "             grid.cv_results_[cv_keys[1]][r] / 2.0,\n",
    "             grid.cv_results_[cv_keys[2]][r]))\n",
    "\n",
    "print('Best parameters: %s' % grid.best_params_)\n",
    "print('Accuracy on train: %.2f' % grid.best_score_)\n",
    "\n",
    "\n",
    "# assess best classifier performance on test set\n",
    "grid_test_score = grid.best_estimator_.score(X_test, y_test)\n",
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "print(f'Accuracy on test set: {grid_test_score:.3f}')\n",
    "# print classification report on test set\n",
    "print(classification_report(y_test, y_pred, target_names=['PD', 'SD-OR']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.673939393939394"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "y_test_predict_proba = grid.predict_proba(X_test)\n",
    "roc_auc_score(y_test, y_test_predict_proba[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and Next Steps\n",
    "Summarize findings here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('PDx_py_combio02': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "00eb3df658785065deb6e848375bdab9b705d39da5f220baeb1f185f534eb99b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}